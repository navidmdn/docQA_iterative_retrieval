seed_everything: 1

trainer:
  accelerator: mps
  devices: 1
  gradient_clip_val: 0.5
  max_epochs: 3
  log_every_n_steps: 5
  val_check_interval: 0.1
  logger: true

model:
  lr: 5e-4
  retriever_model_name: roberta-base

data:
  batch_size: 1
  num_workers: 8
  max_c_len: 400
  max_q_len: 200
  max_q_sp_len: 400
  train_path: data/hotpot/hotpot_train_with_neg_v0.json
  dev_path: data/hotpot/hotpot_dev_with_neg_v0.json
  tokenizer_cp: roberta-base
  preprocessed_data_dir: data/hotpot/preprocessed_train_dataset
